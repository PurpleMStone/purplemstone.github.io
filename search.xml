<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Git笔记(2)--Creating Snapshots]]></title>
    <url>%2F2021%2F04%2F21%2F20210421_Git002%2F</url>
    <content type="text"><![CDATA[初始化一个仓库123mkdir Mooncd Moongit init 在目录Moon下有一个.git隐藏文件夹，可以用以下命令看到： 1ls -a 删除.git： 1rm -rf .git Git Workflow本地directory→staging area (index)→repository Staging Files 用 1git status 查看，标红是因为新建的两个txt文件还没在staging area中。 使用下面的命令将两个文件的变化（新建/删除文件，文件内容更改）存入staging area中： 1git add file1.txt file2.txt 1git add *.txt 1git add . 上面三种方式，（1）就add这两个文件;（2）add所有txt文件;（3）add所有文件 然后再查看，就绿了： Committing Changes提交到仓库 1git commit -m "Initial commit." Committing Best Practices commit的时候文件的变化量应该适中（不要太多，也不要太少） Commit often: 想要记录下某个状态时，就commit Make it mean something 例如：对于两个改变 (1) Bug Fix, (2) Typo 最好不要一起commit，不然不知道改了啥，最好分开commit Skipping the Staging Area使用 -a 选项跳过git add 可以将两个选项 -a 和 -m 合并写成 -am 1git commit -am "Fix the bug" Remove Files12345678910111213$ rm file1.txt$ git statusOn branch masterChanges not staged for commit: (use "git add/rm &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) deleted: file1.txtno changes added to commit (use "git add" and/or "git commit -a")$ git ls-filesfile1.txtfile2.txt 在本地目录下删除file1.txt，但是用git ls-files查看staging area中的文件会发现file1.txt还在其中。使用git add更新staging area然后commit： 123456789101112131415$ git add file1.txt$ git ls-filesfile2.txt$ git statusOn branch masterChanges to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) deleted: file1.txt$ git commit -m "Remove unused code"[master b184de1] Remove unused code 1 file changed, 7 deletions(-) delete mode 100644 file1.txt 除了上面的方法，也可以使用以下方法（git rm）一次性删除本地目录和staging area中的文件： 123456789101112131415$ git rm file2.txtrm 'file2.txt'$ git ls-files$ git statusOn branch masterChanges to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) deleted: file2.txt$ git commit -m "Remove unused code"[master 3fd1e3e] Remove unused code 1 file changed, 1 deletion(-) delete mode 100644 file2.txt Renaming and Moving Files1234567891011121314151617181920212223242526$ mv file1.txt main.js$ git statusOn branch masterChanges not staged for commit: (use "git add/rm &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) deleted: file1.txtUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) main.jsno changes added to commit (use "git add" and/or "git commit -a")$ git add file1.txt$ git add main.jswarning: LF will be replaced by CRLF in main.js.The file will have its original line endings in your working directory$ git statusOn branch masterChanges to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) renamed: file1.txt -&gt; main.js 文件的更名涉及到两个变化，原文件file1.txt删除，以及新文件main.js的创建。 当然，也可以使用便捷的方式： 123456789101112$ git mv file1.txt main.js$ git statusOn branch masterChanges to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) renamed: file1.txt -&gt; main.js$ git commit -m "Refactor code"[master 70800e8] Refactor code 1 file changed, 0 insertions(+), 0 deletions(-) rename file1.txt =&gt; main.js (100%) 注意到0 insertions(+), 0 deletions(-)，改名而已。 Ignoring Files1234567891011$ mkdir logs$ echo hello &gt; logs/dev.log$ git statusOn branch masterUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) logs/nothing added to commit but untracked files present (use "git add" to track) 但是事实上我们并不想将log文件提交。方法：将 logs/ 写入.gitignore中 1$ echo logs/ &gt; .gitignore 用vscode打开文件.gitignore 1$ code .gitignore 可以在 .gitignore 中的下一行写上*.log表示要忽略的文件类型。然后提交 .gitignore 12345678910111213141516$ git statusOn branch masterUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) .gitignorenothing added to commit but untracked files present (use "git add" to track)$ git add .gitignorewarning: LF will be replaced by CRLF in .gitignore.The file will have its original line endings in your working directory$ git commit -m "Add gitignore"[master 9ed82f0] Add gitignore 1 file changed, 2 insertions(+) create mode 100644 .gitignore 之后log文件的改变都会被staging area忽略了： 12345$ echo hello &gt; logs/main.log$ git statusOn branch masternothing to commit, working tree clean 可以看到nothing to commit。 ​ 如果已经用 git add 不小心将 log 文件提交到 staging area 了（在写入.gitignore之前就交了），可以用命令删除 staging area 中的文件。先 help 一下看看用啥选项： 123456789101112$ git rm -husage: git rm [&lt;options&gt;] [--] &lt;file&gt;... -n, --dry-run dry run -q, --quiet do not list removed files --cached only remove from the index -f, --force override the up-to-date check -r allow recursive removal --ignore-unmatch exit with a zero status even if nothing matched --pathspec-from-file &lt;file&gt; read pathspec from file --pathspec-file-nul with --pathspec-from-file, pathspec elements are separated with NUL character 1$ git rm --cached -r logs/ Short Statusgit status 给出的信息易于理解，但是冗长： 12345678910111213141516$ echo sky &gt;&gt; file1.js$ echo sky &gt; file2.js$ git statusOn branch masterChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: file1.jsUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) file2.jsno changes added to commit (use "git add" and/or "git commit -a") 加 -s 选项： 观察 M 的颜色变化，git add 之后 M 由红变绿，?? 变 A 12M：表示modifiedA：表示added Viewing the Staged &amp; Unstaged ChangesMotivation: 有时候在将changes上传到staging area或commit到repository之前，要先看看改了啥，改得对不对。 查看staged changes (在staging area中但是还没commit)： 12345678910111213141516$ git diff --stageddiff --git a/file1.js b/file1.jsindex ce01362..7633964 100644--- a/file1.js+++ b/file1.js@@ -1 +1,3 @@ hello+sky+sundiff --git a/file2.js b/file2.jsnew file mode 100644index 0000000..f5e95e7--- /dev/null+++ b/file2.js@@ -0,0 +1 @@+sky 查看unstaged changes（在本地目录下，不在staging area中）： 1$ git diff 比如在file1.js中将hello 改为 hello world： a是在staging area中的copy，b是本地目录下的copy @@ -1,3 +1,3 @@ 表示旧版本（staging area中的）从第一行开始，有3行（-1,3）；新版本（本地目录下的）从第一行开始，有3行（+1,3） 标红的是旧版本内容，标绿的是新版本内容，白色的是未更改内容。 Visual Diff Tools1234👉 KDiff3👉 P4Merge👉 WinMerge (Windows Only)👉 VSCode 我们选用VSCode来可视化changes。配置： 12345$ git config --global diff.tool vscode$ git config --global difftool.vscode.cmd "code --wait --diff $LOCAL $REMOTE"$ git config --global -e 查看unstaged changes: 1$ git difftool 查看staged changes（旧版本是前一次提交到仓库的版本，新版本是如今在staging area中的版本）： 1234567$ git difftool --stagedViewing (1/2): 'file1.js'Launch 'vscode' [Y/n]? yViewing (2/2): 'file2.js'Launch 'vscode' [Y/n]? y Viewing the History用以下命令查看提交历史： 1$ git log 查看简短描述 (最近更改显示在上面)： 1$ git log --oneline 换显示顺序 (最近更改显示在下面): 1$ git log --oneline --reverse Viewing a Commit可以通过ID查看历史commit，如果ID前几位就唯一标识了某历史commit，那么用前几位即可。 1234567891011121314151617181920212223242526272829$ git log --onelinefdb7fb6 (HEAD -&gt; master) add data62416e2 add filesfde6777 modifiedf264740 modified9ed82f0 Add gitignore70800e8 Refactor coded6f4cc6 Initial commit3fd1e3e Remove unused codeb184de1 Remove unused codedd03e4e Fix the bug3b634ca add Linesa787fca add line568c0fc Initial commit.$ git show 62416commit 62416e293cdb5f7334ea6dc09a8fbb0314eedcc2Author: Stone &lt;1140525895@qq.com&gt;Date: Thu Apr 22 11:32:51 2021 +0800 add filesdiff --git a/file1.js b/file1.jsnew file mode 100644index 0000000..ce01362--- /dev/null+++ b/file1.js@@ -0,0 +1 @@+hello 也可以用HEAD： 1234567891011121314$ git show HEAD~1commit 62416e293cdb5f7334ea6dc09a8fbb0314eedcc2Author: Stone &lt;1140525895@qq.com&gt;Date: Thu Apr 22 11:32:51 2021 +0800 add filesdiff --git a/file1.js b/file1.jsnew file mode 100644index 0000000..ce01362--- /dev/null+++ b/file1.js@@ -0,0 +1 @@+hello HEAD是当前commit的reference, HEAD~1是指从HEAD往后的一个commit，此例中就是ID为62416e2的commit。 也可以查看某历史 commit 中存于 repository 的内容（而不是changes）: 12345$ git show HEAD~1:.gitignorelogs/bin/*.log*.bin 也可以查看某历史 commit 中存于 repository 的所有文件： 123456$ git ls-tree HEAD100644 blob 1cd4d4e7fe27c57dc89d6e68d1f535f00382e563 .gitignore040000 tree 38051ae48accaf0025a257eaa7a3a328e1f0fe56 data100644 blob 29887f938f21333a5eee9dfd0decb4b0a207d855 file1.js100644 blob f5e95e70e524ec32d0200e10ba179ab4c5f13884 file2.js100644 blob ce013625030ba8dba906f756967f9e9ca394464a main.js 格式：ID, 文件类型, 唯一标识符 (根据文件内容确定的), 文件名 data是个文件夹，所以类型为tree，里面有个文件main.txt。 根据文件唯一标识符查看文件内容： 1234567$ git show 3805tree 3805main.txt$ git show f5e95sky f5e95 是 file2.js 的唯一标识符的前几位，该文件的内容只有一行，就是 sky 12345总结：Git Objects👉 Commits👉 Blobs (Files)👉 Trees (Directories)👉 Tags Unstaging Filesfile1.js有两次changes，我们用 git add 将 file1.js 的第一个变化上传到 staging area中了，第二次 change 还在本地目录中。 我们不想同时 commit file1.js 和 file2.js 两个文件的变化。所以要 undo 这个 git add 操作： 1$ git restore --staged file1.js 现在 file1.js 的两次变化都只在本地目录下而不在 staging area 中了。 原理：staging area 从目前的 repository 读取 file1.js 。因为两次变化都还没 commit ，repository 中的 file1.js 就是原始的 (两次变化之前的)。 如果要撤销 file2.js 的 git add 操作。repository 中还没有 file2.js, 所以撤销之后 file2.js 是一个untracked file (用??表示)。 Discarding Local Changes用 1$ git restore . 可以撤销本地目录下的改变。file2.js 依然是untracked file，因为本地目录要从staging area 读取上一次状态，而staging area 中没有 file2.js, 就不知道该做啥。所以要用 1$ git clean 从你的工作目录中删除所有untracked，没有被管理过的文件。 参数说明： 123456789101112$ git clean -husage: git clean [-d] [-f] [-i] [-n] [-q] [-e &lt;pattern&gt;] [-x | -X] [--] &lt;paths&gt;... -q, --quiet do not print names of files removed -n, --dry-run dry run -f, --force force -i, --interactive interactive cleaning -d remove whole directories -e, --exclude &lt;pattern&gt; add &lt;pattern&gt; to ignore rules -x remove ignored files, too -X remove only ignored files Restoring a File to an Earlier Version下面的 demo 显示了删除了 file1.js 后用 git restore 从历史 commit 中恢复此文件。 123456789101112131415161718192021222324252627282930313233$ git rm file1.jsrm 'file1.js'$ git status -sD file1.js$ git commit -m "Delete file1.js"[master 78daaab] Delete file1.js 1 file changed, 1 deletion(-) delete mode 100644 file1.js$ git log --oneline78daaab (HEAD -&gt; master) Delete file1.js133904b commit file1.ls0f62ff0 remove all js filesfdb7fb6 add data62416e2 add filesfde6777 modifiedf264740 modified9ed82f0 Add gitignore70800e8 Refactor coded6f4cc6 Initial commit3fd1e3e Remove unused codeb184de1 Remove unused codedd03e4e Fix the bug3b634ca add Linesa787fca add line568c0fc Initial commit.$ git restore --source=HEAD~1 file1.js$ git status -s?? file1.js]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>job notes-git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL笔记(2)--连接]]></title>
    <url>%2F2021%2F04%2F20%2F20210420_SQL002%2F</url>
    <content type="text"><![CDATA[Inner Joins (内连接)1234SELECT order_id, o.customer_id, first_name, last_nameFROM orders oINNER JOIN customers c ON o.customer_id = c.customer_id 返回表orders在表customers中有对应record的项 o和c分别是orders和customers的别名，以简化代码 关键字INNER可省略 跨数据库连接123456USE sql_store; -- 选择了数据库sql_store为当前数据库SELECT *FROM order_items oiJOIN sql_inventory.products p -- 另一个数据库sql_inventory ON oi.product_id = p.product_id 自连接将表和自己连接，但是给不同的别名以区分。如下，manager也是一名员工，其信息也在表employees中，用自连接可以得到employee和TA的manager的具体员工信息。 123456789USE sql_hr; -- 选择了数据库sql_hr为当前数据库SELECT e.employee_id, e.first_name, m.first_name AS managerFROM employees eJOIN employees m ON e.reports_to = m.employee_id 多表连接12345678910111213USE sql_store;SELECT o.order_id, o.order_date, c.first_name, c.last_name, os.name AS statusFROM orders oJOIN customers c ON o.customer_id = c.customer_idJOIN order_statuses os ON o.status = os.order_status_id 表orders先和表customers连接，然后与表order_statuses连接。 IN 运算符12345678910SELECT *FROM customers-- WHERE state = 'VA' OR state = 'GA' OR state = 'FL'-- 用IN改写：WHERE state IN ('VA', 'GA', 'FL')-- WHERE state NOT IN ('VA', 'GA', 'FL') -- 返回不在这些州的 records-- 这样是错的：WHERE state = 'VA' OR 'GA' OR 'FL' -- 因为我们不能用OR连接布尔表达式state = 'VA'和字符串'GA' BETWEEN 运算符12345SELECT *FROM customers-- WHERE points &gt;= 1000 AND points &lt;=3000-- 改写为：WHERE points BETWEEN 1000 AND 3000 1234-- 也可用于非数值SELECT *FROM customersWHERE birth_date BETWEEN "1990-01-01" AND "2000-01-01" LIKE 运算符1234567891011121314151617181920-- 字符串模式匹配SELECT *FROM customersWHERE last_name LIKE 'b%' -- 得到last name以'B'或'b'开头的recordsWHERE last_name LIKE 'brush%' -- 得到last name以“brush”开头的recordsWHERE last_name LIKE '%b%' -- 表示'b'前后可以有任意字符数('b'在开头、中间、结尾出现皆可)WHERE last_name LIKE '%y' -- 得到last name以'y'结尾的recordsWHERE last_name LIKE '_____y' -- 得到last name以'y'结尾且只有6个字符('_'填补表示任意字符)的recordsWHERE last_name LIKE 'b____y' -- 运行后得到last name以'b'开头以'y'结尾且只有6个字符的record(本例中为'Boagey') 123/***SUMMARY**/ % any number of characters_ single character REGEXP 运算符12345678910111213141516171819202122232425262728-- regular expression (REGEXP) 正则表达式SELECT *FROM customersWHERE last_name LIKE '%field%'-- WHERE last_name REGEXP 'field'WHERE last_name REGEXP '^field' -- last name must starts with "field"WHERE last_name REGEXP 'field$' -- last name must ends with "field"/* use '|' for multiple search pattern */ WHERE last_name REGEXP 'field|mac|rose' -- last name must contains "field" or "mac" or "rose"WHERE last_name REGEXP 'field$|mac|rose' -- last name must ends with "field" or contains "mac"/"rose"WHERE last_name REGEXP '[gim]e' -- last name must contains "ge"/"ie"/"me"WHERE last_name REGEXP 'e[gim]' -- last name must contains "eg"/"ei"/"em"WHERE last_name REGEXP '[a-h]e'-- the same as WHERE last_name REGEXP '[abcdefgh]e' 12345^ beginning$ end| logical or[abcd][a-f] IS NULL 运算符1234SELECT *FROM customersWHERE phone IS NULL -- 返回没有phone(该字段为NULL)的recordsWHERE phone IS NOT NULL -- phone不为空 ORDER BY 子句默认是按照主键（primary key）排序，使用ORDER BY 子句可以指定排序的键 1234SELECT *FROM customersORDER BY first_name -- 根据first_name字段值升序排序ORDER BY first_name DESC -- 根据first_name字段值降序排序 1234SELECT *FROM customersORDER BY state DESC, first_name --先根据state降序排列，state相同的根据first_name升序排列 1234-- birth_date不在选出来的列里，still workSELECT first_name, last_nameFROM customersORDER BY birth_date LIMIT 子句12345SELECT *FROM customersLIMIT 3 -- 返回前3个recordsLIMIT 300 -- 300 &gt; #record, 返回全部recordsLIMIT 6, 3 -- 跳过前6个records，返回第7，8，9个records]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>job notes-database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL笔记(1)--基础语句]]></title>
    <url>%2F2021%2F04%2F20%2F20210420_SQL001%2F</url>
    <content type="text"><![CDATA[SELECT 子句从一张表（customers）中选取某些列 123456SELECT first_name, last_name, points, points * 10 + 100 AS "discount factor" -- 可以进行数学运算,AS来renameFROM customers 12SELECT DISTINCT state -- DISTINCT 只保留重复项中的一项FROM customers WHERE 子句过滤作用，根据条件选择records (各个WHERE子句只是提供不同的示例，运行时选择一个WHERE子句，其余注释掉，下文同) 12345SELECT *FROM customersWHERE state = 'va' -- va大小写一样的WHERE state &lt;&gt; 'va' -- not in VAWHERE birth_date &gt; '1990-01-01' -- born after 1990/01/01 运算符有： 123456&gt;&gt;=&lt;&lt;==(not equal) != or &lt;&gt; AND, OR, NOT 运算符123SELECT *FROM customersWHERE NOT (birth_date &gt; '1990-01-01' OR points &gt; 1000) AND优先级高于OR IN 运算符12345678910SELECT *FROM customers-- WHERE state = 'VA' OR state = 'GA' OR state = 'FL'-- 用IN改写：WHERE state IN ('VA', 'GA', 'FL')-- WHERE state NOT IN ('VA', 'GA', 'FL') -- 返回不在这些州的 records-- 这样是错的：WHERE state = 'VA' OR 'GA' OR 'FL' -- 因为我们不能用OR连接布尔表达式state = 'VA'和字符串'GA' BETWEEN 运算符12345SELECT *FROM customers-- WHERE points &gt;= 1000 AND points &lt;=3000-- 改写为：WHERE points BETWEEN 1000 AND 3000 1234-- 也可用于非数值SELECT *FROM customersWHERE birth_date BETWEEN "1990-01-01" AND "2000-01-01" LIKE 运算符1234567891011121314151617181920-- 字符串模式匹配SELECT *FROM customersWHERE last_name LIKE 'b%' -- 得到last name以'B'或'b'开头的recordsWHERE last_name LIKE 'brush%' -- 得到last name以“brush”开头的recordsWHERE last_name LIKE '%b%' -- 表示'b'前后可以有任意字符数('b'在开头、中间、结尾出现皆可)WHERE last_name LIKE '%y' -- 得到last name以'y'结尾的recordsWHERE last_name LIKE '_____y' -- 得到last name以'y'结尾且只有6个字符('_'填补表示任意字符)的recordsWHERE last_name LIKE 'b____y' -- 运行后得到last name以'b'开头以'y'结尾且只有6个字符的record(本例中为'Boagey') 123/***SUMMARY**/ % any number of characters_ single character REGEXP 运算符12345678910111213141516171819202122232425262728-- regular expression (REGEXP) 正则表达式SELECT *FROM customersWHERE last_name LIKE '%field%'-- WHERE last_name REGEXP 'field'WHERE last_name REGEXP '^field' -- last name must starts with "field"WHERE last_name REGEXP 'field$' -- last name must ends with "field"/* use '|' for multiple search pattern */ WHERE last_name REGEXP 'field|mac|rose' -- last name must contains "field" or "mac" or "rose"WHERE last_name REGEXP 'field$|mac|rose' -- last name must ends with "field" or contains "mac"/"rose"WHERE last_name REGEXP '[gim]e' -- last name must contains "ge"/"ie"/"me"WHERE last_name REGEXP 'e[gim]' -- last name must contains "eg"/"ei"/"em"WHERE last_name REGEXP '[a-h]e'-- the same as WHERE last_name REGEXP '[abcdefgh]e' 12345^ beginning$ end| logical or[abcd][a-f] IS NULL 运算符1234SELECT *FROM customersWHERE phone IS NULL -- 返回没有phone(该字段为NULL)的recordsWHERE phone IS NOT NULL -- phone不为空 ORDER BY 子句默认是按照主键（primary key）排序，使用ORDER BY 子句可以指定排序的键 1234SELECT *FROM customersORDER BY first_name -- 根据first_name字段值升序排序ORDER BY first_name DESC -- 根据first_name字段值降序排序 1234SELECT *FROM customersORDER BY state DESC, first_name --先根据state降序排列，state相同的根据first_name升序排列 1234-- birth_date不在选出来的列里，still workSELECT first_name, last_nameFROM customersORDER BY birth_date LIMIT 子句12345SELECT *FROM customersLIMIT 3 -- 返回前3个recordsLIMIT 300 -- 300 &gt; #record, 返回全部recordsLIMIT 6, 3 -- 跳过前6个records，返回第7，8，9个records]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>job notes-database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法笔记(1)]]></title>
    <url>%2F2021%2F03%2F12%2F20210312_DongAlgNote%2F</url>
    <content type="text"><![CDATA[数组与链表数据结构的存储方式只有两种：数组（顺序存储）和链表（链式存储）。 那些多样化的数据结构，究其源头，都是在链表或者数组上的特殊操作，API 不同而已 数组由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间。但正因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)；而且你如果想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N)。 链表因为元素不连续，而是靠指针指向下一个元素的位置，所以不存在数组的扩容问题；如果知道某一元素的前驱和后驱，操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。但是正因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问；而且由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。 数据结构基本操作遍历 + 访问：增删查改（在不同的应用场景，尽可能高效地增删查改） 方式：线性-for/while；非线性-递归]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>job notes-algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(7)-Visual to Sound Generating Natural Sound for Videos in the Wild]]></title>
    <url>%2F2020%2F12%2F25%2F20201225_VisualToSound%2F</url>
    <content type="text"><![CDATA[任务：从输入的视频中直接预测raw声音信号 方法：编码-解码架构，即视频编码器+音频生成器（分层RNN） 建模：条件生成问题。训练一个有条件的生成模型以从输入的视频中合成raw声音波形。 估计条件概率： p(y_{1},y_{2},...,y_{n}|x_{1},x_{2},...,x_{m})$x_{1},x_{2},…,x_{m}$是输入视频帧的表示；$y_{1},y_{2},…,y_{n}$是输出声音波形的值（取值为0~255的整数序列）。原始波形样本是范围从-1到1的实数值，文中重新缩放和线性量化它们到256个bins。通常$m&lt;&lt;n$，因为音频的采样率远高于视频的采样率。 Sound Generator采用的采样频率为：16kHz 问题：序列长度很长 解决方法：选用SampleRNN为声音生成器（原因：其从粗到细的结构使模型能够生成非常长的序列，每一层的循环结构捕捉到遥远样本之间的依赖关系。） 具体：1）细节层是多层感知机（MLP），获取下一个粗糙层（上层）的输出和前面的$k$个样本，以生成一个新样本。在训练过程中，波形样本（实数值，从-1到1）被线性量化到从0到255的整数范围，可以将最细的层的MLP看成是256-类分类器，在每个timestep预测得到一个样本（然后映射回实值，获得最终波形）。 2）粗糙层可以是GRU, LSTM或其他的RNN变体。包含多个波形样本(图中为2个)的节点意味着该层基于前一个timestep以及更粗层的预测，在每个timestep共同预测多个样本。 Video EncoderFrame-to-frame method x_{i}=V(f_{i})$f_{i}$和$x_{i}$分别是视频的第$i$帧和该帧的表征。$V(.)$是在ImageNet上预先训练的VGG19网络的fc6特征提取操作，$x_{i}$是一个4096维的向量。在该模型中，将帧表征与声音生成器最粗层RNN的节点（样本）统一连接，对视觉信息进行编码，如图3(b)所示（内容以绿色虚线框表示）。 视频与音频采样率不同的问题解决：对于每个$x_{i}$，重复$s$次，其中 s=\lceil \frac{sr_{audio}}{sr_{video}}\rceil,\quad (``sr"\ means\ sampling\ rate)只将视觉特征提供给SampleRNN的最粗糙层，因为这一层很重要，因为它指导所有更细的层的生成以及提高计算效率。 Sequence-to-sequence method提取VGG19网络的fc6特征作为每一帧的表征，然后用RNN处理作为视频编码器，使用视频编码器的最后一个隐藏状态初始化声音发生器的最粗层RNN的隐藏状态，然后开始声音生成。此时声音生成任务变为： p(y_{1},y_{2},...,y_{n}|x_{1},x_{2},...,x_{m})=\prod\limits^{n}_{i=1}p(y_{i}|H,y_{1},...,y_{i-1})$H$表示视频编码RNN的最后一个隐藏状态或等效的声音发生器最粗糙层RNN的初始隐藏状态。 视频与音频采样率不同的问题解决：不像上面提到的基于帧的模型中明确地强制视频帧和波形样本之间的对齐。在这个序列到序列模型中，我们期望模型通过编码和解码来学习这两种模式之间的对齐。 Flow-based methodMotiv：视觉领域的运动信号，虽然有时很微小，但对于合成真实且同步良好的声音是至关重要的。 方案：增加一个基于光流的深度特征以明确捕获运动信号。与序列到序列方法不同之处为 x_{i}=cat[V(f_{i}),F(o_{i})]$o_{i}$是第$i$帧的光流，$F(.)$是提取基于光流的深度特征的函数（非学习得到）。 Visual to Sound: Generating Natural Sound for Videos in the Wild]]></content>
      <categories>
        <category>Visual Sound</category>
      </categories>
      <tags>
        <tag>paper notes-visual sound</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(6)-Visually Indicated Sounds]]></title>
    <url>%2F2020%2F12%2F25%2F20201225_VisuallyIndicatedSound%2F</url>
    <content type="text"><![CDATA[Sound Representation计算声音特征的方法：将声波$w(t)$分解为子带包络$s_{n}(t)$（将声波滤波然后应用非线性）。1）在等效矩形带宽(ERB)尺度上应用40个带通滤波器$f_{n}$(加上一个低通和高通滤波器)，并取响应的希尔伯特包络线；2）将包络下采到90Hz（约为3样本/帧）并压缩。 s_{n}=D(|(w*f_{n})+jH(w*f_{n})|)^{c}$H$是希尔伯特变换，$D$表示下采样，压缩常数$c=0.3$。由此产生的表示被称为耳蜗图（cochleagram）。 一般来说，撞击声如何捕捉材料的属性?为了从经验上评测这一点，文章使用子带包络作为特征向量，训练了一个线性支持向量机来预测数据库中的声音由哪个材料发出。文章对训练集重新采样，使每个类包含相同数量的撞击声(每类260个)。最终得到的材料分类器具有45.8% (chance = 5.9%)的分类平均精度(即每类精度值的平均值)，其混淆矩阵如图3(b)所示。这些结果表明，撞击声传达了有关材料的重要信息，因此，如果一个算法能够学习从图像中准确预测这些声音，它就会有关于材料类别的隐含知识。 Predicting visually indicated sounds将此任务建模为一个回归问题，目标是将一个视频帧序列映射为一个声频特征序列。使用的模型是RNN，以颜色和运动（motion）信息作为输入，预测出声频波形的子带包络。最后，从声音特征中产生波形。 Regressing sound features输入图像序列：$I_{1}, I_{2}, …, I_{N}$ 输出声音特征序列：$\mathop{s_{1}}\limits ^{\rightarrow}, \mathop{s_{2}}\limits ^{\rightarrow}, \mathop{s_{T}}\limits ^{\rightarrow}, where \mathop{s_{t}}\limits ^{\rightarrow}\in \mathbb{R}^{42}$ 这些声音特征对应于图4中所示的耳蜗块。文章使用循环神经网络(RNN)来解决这个回归问题，它将卷积神经网络(CNN)计算的图像特征作为输入。 图像表示：如何表示运动（motion）信息？计算每一帧的spacetime图像，即三个通道是上一帧、当前帧和下一帧灰度版本的图像。对于每一帧$t$，通过拼接帧$t$的spacetime图像和第1帧的颜色图像的CNN特征来构建输入特征向量$x_{t}$，即 x_{t}=[\phi(F_{t}),\phi(I_{1})]文章中训练的两种方式：1）从零开始初始化CNN，然后和RNN一起训练它；2）用一个为ImageNet分类训练的网络的权值初始化CNN。当使用预训练时，从卷积层中预计算特征，并仅对完全连接的层进行微调。 声音预测模型：使用基于LSTM的RNN模型。为了补偿视频和音频采样率之间的差异，文章中复制每个CNN特征向量$k$次（文章中使用$k=3$） k=\lfloor T/N\rfloor由此得到与声音特征序列等长的CNN特征序列$x_{1}, x_{2}, …, x_{N}$。在RNN的每个timestep，文章中使用当前图像特征向量$x_{t}$来更新隐藏变量$h_{t}$，然后通过一个仿射变换得到声音特征。为了使学习问题更简单，文中使用PCA在每个时间步长的42维特征向量投影到10维空间，然后预测这个低维向量。对网络进行评估时，反求PCA变换以获得声音特征。 文章使用随机梯度下降以Caffe共同训练RNN和CNN。它有助于收敛去除dropout和剪辑大的梯度。当从头开始训练时，文中通过对视频进行裁剪和镜像转换来增强数据。文中也使用多个LSTM层（数量取决于任务）。 Generating a waveform问题：如何从声音特征中产生声波？ 简单参数综合法：迭代地将子带包络加到白噪声样本上(文中只使用了一次迭代)。这种方法对于检查音频特征所捕获的信息非常有用，因为它代表了从特征到声音的直接转换。 对于产生对于人耳似是而非的声音的任务，在从特征到波形的转换过程中，先施加一个强的自然声音是更有效的。因此使用基于实例的合成方法，该方法将声音特征的窗口捕捉到训练集中最接近的样本上。文中通过拼接预测的声音特征$\mathop{s_{1}}\limits ^{\rightarrow}, \mathop{s_{2}}\limits ^{\rightarrow}, …, \mathop{s_{T}}\limits ^{\rightarrow}$（或它们的一个子序列）形成一个查询向量，在$L_{1}$距离测量的训练集中寻找其最近的邻居，并传递相应的波形。 项目网址]]></content>
      <categories>
        <category>Visual Sound</category>
      </categories>
      <tags>
        <tag>paper notes-visual sound</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(5)-The Visual Microphone Passive Recovery of Sound from Video]]></title>
    <url>%2F2020%2F12%2F22%2F20201222_VisualMicrophone%2F</url>
    <content type="text"><![CDATA[简介现象：声音到达物体会在物体表面引起微小振动。 做法：使用物体的高速视频提取微小振动，部分恢复（造成振动的）声音。 具体：1）从一系列不同特性的物体的高速连续镜头中恢复声音； ​ 2）使用真实和仿真数据来评测那些影响了可视化地恢复声音的因素； ​ 3）声音恢复质量评价指标：可理解性（intelligibility）、SNR；直接对比输入和恢复出来的信号； ​ 4）探索如何利用普通用户相机的卷帘快门（rolling shutter）从而从标准帧率视频中恢复出声音；使用所提方法的空间分辨率来可视化声音引起的振动是如何随着物体表面变化的，以之恢复物体的振动模式。 Keywords：远程声音采集；视频中的声音；可视化声学。 Introduction描述：声音到达某物品 → 1）物品表面跟随周围介质移动 OR 2）根据其振动模式发生形变。 应用场景：声音引起物体振动的现象被用于远程声音采集，并在监视和安防方面有重要应用，如在远处窃听谈话。远程声音采集的现有方法本质上是积极（active）的，需要将一个激光束或pattern投射到振动表面。 本文观察：只需要物体的高速视频，声音引起的物体振动通常能够产生足够的视觉信号来部分恢复出该声音。 本文贡献：提出一个消极的从视频中恢复声音信号的方法。视觉上检测微小物体振动→将振动转回音频信号（使得日常物品变成潜藏的麦克风）。做法：1）使用高速摄像机将物体视频；2）在一个Complex steerable pyramid (CSP)（建立在视频上）的维度上提取局部运动信号；3）这些局部信号被对齐并取平均，得到一个单一的一维运动信号，该信号捕捉对象随时间的全局运动；4）进一步滤波和去噪，得到恢复出来的声音。 对比积极方法：恢复效果不如积极方法；但是优点有 1）对于纹理物体和光照良好的场景不需要提供积极照明；2）除了高速摄像机外无需额外的传感器或检测模块；3）无需回射或反射振动表面（区别于激光麦克风）；4）没有对相对于相机的表面方向施加明显的约束；5）产生了一个声音的空间测量，可用于分析物品中声音引起的形变。 讨论：虽然声音可以穿透大多数物质，但并不是所有的物体和材料都能很好地进行视觉声音恢复。声波在材料中的传播取决于多种因素，如材料的密度和可压缩性，以及物体的形状。文章进行对照实验，测量了不同物体和材料对已知和未知声音的反应，并评估文章所提技术对于从高速视频中恢复声音的能力。 Related Work传统麦克风的工作原理是将内部膜片的运动转化为电信号。膜片的设计使其在声压下容易移动，因此它的运动可以被记录下来并解释为音频。激光麦克风的工作原理与此类似，但它测量的是一个遥远物体的运动，本质上是将物体作为一个外部膜片。这是通过记录激光对物体表面的反射来实现的。最基本的激光麦克风记录反射激光的相位，以激光波长作模得到物体的距离。激光多普勒测振仪(LDV)通过测量反射激光的多普勒频移来确定反射面速度，从而解决相位包裹的模糊性。这两种类型的激光麦克风都可以从很远的距离恢复高质量的音频，但依赖于激光和接收器相对于具有适当反射比的地面的精确定位。 Zalevsky等人通过使用失焦高速相机来记录反射激光散斑模式的变化，解决了其中的一些局限性。他们的工作允许接收器的定位有更大的灵活性，但仍然依赖于记录反射激光。相比之下，本文的技术不依赖于主动照明。 本文方法依赖于从视频中提取极其细微运动的能力，因而也与对这些运动进行放大和可视化的工作有关。这些工作侧重于小运动的可视化，而本文侧重于测量这些运动并利用它们来恢复声音。本文工作中使用的局部运动信号来自Simoncelli等人提出的Complex steerable pyramid (CSP)中的相位变化，因为这些变化被证明非常适合于视频中微小动作的恢复。然而，也有可能使用其他技术来计算局部运动信号。例如，经典的光流和点相关方法在之前的视觉振动传感工作中被成功地使用。由于本文方法的输出是单个振动物体的一维运动信号，因而能够对输入视频中的所有像素进行平均，并在千分之一像素的数量级上处理极其微小的运动。 Recovering Sound from Video 输入：物体的高速视频（1kHz~20kHz）$V(x,y,t)$ 假设：物体和相机的相对运动是由声音信号$s(t)$引起的振动主导的 目标：从$V$得到$s(t)$ 步骤：1）根据不同的方向$θ$和尺度$r$将$V$分解成多个空间子带； ​ 2）计算每个像素、方向和尺度上的局部运动信号；通过一系列的平均和对齐操作将这些运动信号组合起来，为物体产生一个单一的全局运动信号； ​ 3）对物体的运动信号使用音频去噪和滤波技术，以获得恢复出来的声音。 Computing Local Motion Signals使用$V$的CSP表示中的相位变化来计算局部运动。 CSP：将$V$中的每一帧根据不同的方向和尺度分解成复数子带的滤波器组。该变换的基础方程是带尺度和方向的兼具余弦和正弦相位的Gabor-like小波。每一对类余弦和类正弦滤波器都可以用来分离局部小波的振幅和它们的相位。具体地说，每个尺度$r$和方位$θ$是一个复数图像，可以用幅值$A$和相位$φ$表示为： A(r,\theta,x,y,t)e^{i\varphi (r,\theta,x,y,t)}取这个等式中计算的局部相位$φ$，从参考帧$t_{0}$(通常是视频的第一帧)的局部相位中减去它们，计算相位变化 \varphi_{v} (r,\theta,x,y,t)=\varphi (r,\theta,x,y,t)-\varphi (r,\theta,x,y,t_{0})对于较小的运动，这些相位变化近似正比于图像结构在相应方向和尺度上的位移。 Computing the Global Motion Signal对于CSP的每个尺度$r$和方位$θ$求局部运动信号的加权平均： \Phi_{i}(r,\theta,t)=\sum\limits_{x,y}A(r,\theta,x,y)^{2}\varphi_{v} (r,\theta,x,y,t)求加权平均的原因：局部相位在没有太多纹理的区域是模糊的，导致这些区域的运动信号是有噪声的。CSP的振幅A给出了纹理强度的度量，因此可以通过(平方)振幅来加权每个局部信号。 对齐： t_{i}=arg\max\limits_{t_{i}}\Phi_{0}(r_{0},\theta_{0},t)^{T}\Phi_{i}(r_{i},\theta_{i},t-t_{i})得到全局运动信号： \hat{s}(t)=\sum\limits_{i}\Phi_{i}(r_{i},\theta_{i},t-t_{i})归一化到[-1,1]的范围。 Denoising目标：改善全局运动信号的SNR 观察到的现象：低频的高能量噪声通常与音频不一致 方法：应用高通Butterworth滤波器（截断频率为20-100Hz） 滤除加性噪声：目标是accuracy，用spectral subtraction；目标是可理解性，用感知驱动的语音增强算法（通过计算一个贝叶斯最优估计去噪信号的成本函数，考虑到人类对语音的感知）。本文的结果是自动使用二者之一的算法来去噪的。 恢复信号的不同频率可能会被记录对象不同地调制。第4.3节将展示如何使用已知测试信号来描述一个物体如何衰减不同频率，然后在新的视频中使用该信息来均衡从同一物体(或类似物体)中恢复的未知信号。 Experiments第一组实验测试了可以从不同物体上恢复的频率范围。通过扬声器播放线性渐变频率的声音信号，然后观察哪些频率可以通过本文技术恢复。第二组实验集中在从视频中恢复人类语言。这些实验使用了来自TIMIT数据集的几个标准语音示例，以及通过扬声器播放的人类受试者的现场语音(扬声器被一个会说话的人替换)。 Sound Recovery from Different Objects/Materials 在几乎所有的结果中，恢复的信号在较高的频率中是较弱的。这是意料之中的，因为更高的频率产生更小的位移，并且被大多数材料严重衰减。然而，较高频率的功率下降不是单调的，可能是由于振动模式的刺激。毫不奇怪，较轻的物体更容易移动，比惰性的物体更容易支持更高频率的恢复。 Speech Recovery评测指标： (1) 评测accuracy： Segmental Signal-to-Noise Ratio (SSNR) 随时间的平均局部信噪比; (2) 评测intelligibility： perceptually-based metric (3) 评测恢复质量：Log Likelihood Ratio (LLR)，评测恢复信号的谱形状与原始干净信号的谱形状有多接近 更高的帧率导致曝光时间减少，因此图像噪声更多，这就是为什么20,000FPS结果图比2200Hz时的结果噪声更大 VM和LDV结果相近，而LDV需要积极照明（必须在物体上粘上一条反反射胶带以便激光从物体上反射回来回到振动计上） Transfer Functions and Equalization可以使用第4.1节中的斜坡信号来表征物体的(可视的)频率响应，以提高从该物体的新观测中恢复的信号质量。理论上。如果认为物体是线性系统,可以使用维纳反卷积估计与该系统相关联的复数传递函数，并且传递函数可以用来以一种最优的方式(在均方误差意义上的)解卷积新的观测信号。然而，在实践中，这种方法很容易受到噪声和非线性artifacts的影响。因此，本文描述了一种更简单的方法，首先使用训练实例（线性斜坡）的短时间傅里叶变换在粗尺度上计算频率传递系数，然后使用这些传递系数使新的观测信号相等。 转移系数是从一对输入/输出的信号的短时功率谱中提取出来的。每个系数对应于观察到的训练信号的短时功率谱的一个频率，并作为随时间变化的频率幅值的加权平均被计算。每一时刻的权值由对准的输入训练信号的短时功率谱给出。由于输入信号一次只包含一个频率，这个加权方案忽略了图2(b)中所示的倍频等非线性artifacts。 一旦有了传输系数，我们就可以用它们来平衡新的信号。有很多方法可以做到这一点。将增益应用于新信号短时功率谱的频率上，然后在时域重新合成信号。应用于每个频率的增益与其相应的传递系数的倒数成正比，该系数上升到某个指数k。 表2显示了应用从薯片袋导出的均衡器到从同一物体恢复的语音序列的结果。在没有噪声的情况下，k设为1，但广谱噪声压缩了估计的传递系数的范围。使用更大的k可以弥补这一点。在其中一个女性语音示例上手动调整k值，然后将得到的均衡器应用于所有六个语音示例。由于这种均衡是为了提高恢复信号的可信度而不是语音的可理解性，因此使用谱减法来去除噪声。 注意，校准和均衡是可选的。特别是，本文中除表2之外的所有结果都假定不预先知道被记录物体的频率响应。 AnalysisObject response (A): 物体相应声音并移动，将空气压力转化为表面位移。 Processing (B): 将录制的视频转换成恢复的声音。 Object response (A) 图7(b)：300Hz纯音测试，大多数物体的运动在声压（音量）上近似呈线性。结论：A可建模为LTI系统。 图7(c)：斜坡信号（20Hz到2200Hz）测试，将A建模为LTI系统，用这个斜坡信号来恢复系统的脉冲响应。这是通过使用维纳反卷积用已知的输入对观察到的斜坡信号(这一次是由LDV记录的)进行反卷积来实现的。图7 (c)显示了从恢复的脉冲响应中得到的频率响应。从这张图中可以看到，大多数物体在低频率的响应比高频率的响应更强(正如预期的那样)，但是这种趋势不是单调的。 D_{mm}(\omega)\approx \boldsymbol{A}(\omega)S(\omega)$\boldsymbol{A}(\omega)$: 转移函数 $S(\omega)$: 声谱 $D_{mm}(\omega)$: 运动谱 项目网址]]></content>
      <categories>
        <category>Visual Sound</category>
      </categories>
      <tags>
        <tag>paper notes-visual sound</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(4)：CNN频域学习(2)]]></title>
    <url>%2F2020%2F12%2F04%2F20201204_CNNinFrequence2%2F</url>
    <content type="text"><![CDATA[Faster Neural Networks Straight from JPEGMotivation1、缩短图像解码时间。大部分图片都是通过JPEG格式进行存储，JPEG格式转换为RGB需要解码。而如果通过频域学习，解码时只需要从霍夫曼编码中获取DCT系数即可，不需要完全解码得到RGB图像； 2、让模型更高效。CNN模型的优势是表达能力强（参数很多），所需先验少。但是先验少，所以需要大量参数，使得CNN模型中存在大量冗余计算。频域学习其实是一个先验，如果数据分布和该先验一致，那么达到同样的效果，模型可以更简单，所需要的训练数据可以更少。 Method Evaluation在ImageNet上实验。目标是准确率高且运行速度快。 BaselineVanilla ResNet-50, 输入为RGB图像。Top-5错误率7.4%左右，速度200 image/s： 以YCbCr为输入，效果与RGB差不多。期望的效果是在图中往右下发展（右：速度快；下：错误率低）。 希望运行速度更快：1）shorter ResNet-50 (减少网络层数)；2）thinner ResNet-50 (减少每层的通道数) 结论：shorter ResNet-50优于thinner ResNet-50。浅灰色的“Remove N ID Blocks”的线形成了帕累托前沿(Pareto front)，显示了“non-dominated”网络的集合，或者是那些在速度和准确性之间做出最佳权衡的网络。 Training networks on DCT inputs 问题1：针对不同的输入尺寸如何处理？ RGB图像大小：(224, 224, 3) DCT系数： 1) Y-(28, 28, 64)； ​ 2) Cb/Cr-(14, 14, 64) 解决：在进入网络之前combine Y和Cb、Cr 1. DCT Early Merge architectures：1）下采Y（“DownSampling”）；2）上采Cb、Cr（“UpSampling”） 结论： 1）DownSampling：fast (450 image/s) but high error； ​ 2） UpSampling：slower but lower error; 问题2：UpSampling的错误率比baseline高 可能的原因：感受野过大。传到baseline ResNet-50的中间层时感受野约为70像素；而UpSampling模型的相应感受野达到了110像素。这是因为DCT输入层的[stride, receptive field]是[8, 8]，而经典输入层该值为 [1, 1]。 直观地说，要求网络学习110px宽的感受野，但没有给它足够的层或计算能力来做到这一点。 解决：创造了一个Receptive Field Aware (RFA) 模型→UpSampling-RFA。做法是给神经网络的前层增加额外的步长1模块。此时逐层的感受野增长变得更平滑，近似与baseline ResNet-50相匹配。 如果UpSampling通过可学反卷积而非像素复制得到，则错误率可以进一步降低，达到目前为止最好的模型：Deconvolution-RFA（错误率6.98%；加速1.29倍）。 效果：沿着DCT Early Merge线的其他模型现在形成了新的帕累托前沿，在误差和速度的权衡方面超越了以前的模型。 2. DCT Late Merge architectures 实验发现允许亮度分支多层计算才能获得较高的准确率，而色度路径可以在较少的计算层数下不损害准确率。换句话说，1) 将Y通道放到网络的前面，而Cb/Cr信息在中途注入，其效果与 2) 从前面开始全部三个通道的运算 一样好，而方法1)节省了计算。 Late-Concat-RFA：receptive field aware version； Late-Concat-RFA-Thinner：通过使用更少过滤器而调整速度的版本。加速1.77倍，错误率相近。 结论：帕累托前沿再次前移。 Discussion有趣的是，颜色信息在网络后期（当它与从亮度中学到的更高层次的概念相结合时）才被需要。在这一点上猜测可能是学习中级概念（例如:草或狗毛）需要在其与空间上不那么精确的颜色信息（例如:绿色或棕色）结合之前，精细的亮度边缘进行了好几层处理变成纹理。可以从ResNet-50从RGB像素学习到的更高频率的黑白边缘和更低频率（或常数）的颜色检测器中预期这个结果。 许多边缘检测器基本上都是黑白的，在亮度空间中操作。许多颜色特征要么在空间上是恒定的，要么在频率上是较低的，它们可能只是用来将粗略的颜色信息传递给需要它的更高层次。我们从2012年就看到过这样的滤波器;我们是否应该期望直到网络后期才需要颜色? 速度与准确率：速度的提升是由于输入层和后续层上的数据量较小。准确率提升的主要原因是 DCT 表示的具体使用，结果对图像分类非常有效。只需将 ResNet-50 的第一个卷积层替换为stride为 8 的DCT 变换，即可获得更好的性能。它甚至比完全相同形状的学习得到的变换（learned transform）效果更好。使用更大的感受野和stride（8）表现更好，而硬编码第一层比学习得到第一层效果更好。残差网络在 2015 年得到 ImageNet 上最先进的性能，只需用DCT 替换第一层，就会进一步提高SOTA。 CNN频域学习博客讲解 Faster Neural Networks Straight from JPEG Faster Neural Networks Straight from JPEG 博客讲解]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>paper notes-deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(3)：CNN频域学习(1)]]></title>
    <url>%2F2020%2F12%2F03%2F20201203_CNNinFrequence%2F</url>
    <content type="text"><![CDATA[On using CNN with DCT based Image DataMotivation对于高分辨图像、视频，输入数据量大，CNN运算多→从图像压缩算法JPEG得到启发，经过DCT变换将空域数据转换到频域处理，压缩输入数据量。 Method Results实验数据集：CIFAR10，MNIST Discussion文章直接用DCT系数替代RGB作为CNN输入，处理方法简单直接。Motivation是数据压缩，但是没给出输入数据量减少的实验结果（只是作为future work），而准确率提升也不明显。 On using CNN with DCT based Image Data]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>paper notes-deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(2)：AdderNet]]></title>
    <url>%2F2020%2F12%2F02%2F20201202_AdderNet%2F</url>
    <content type="text"><![CDATA[Motivation目标：设计更加高效的深度神经网络，可以在资源有限的移动设备运行。 现有工作的局限性：常规的卷积基于乘法，代价较高；用二值滤波器替换卷积的工作如BNN等会带来较大的识别准确率下降。 文章思路：常规卷积本质上是一种互相关（输入图像与卷积核之间的相似度度量）。可以用更高效的相似度度量方法来替换常规卷积，使得度量中只包含代价较小的加法操作→AdderNet AdderNet开局公式 Y(m,n,t)=\sum\limits_{i=0}^{d}\sum\limits_{j=0}^{d}\sum\limits_{k=0}^{c_{in}}S(X(m+i,n+j,k),F(i,j,k,t))F： 卷积核（滤波器）(尺寸$d×d$) 当d=1时，该公式表示全连接层的计算 X：特征图 S：预定义的相似度测量方法，例如互相关中$S(x,y)=x\times y$ 从上述公式出发，文章改变S，使用L1距离测量F和X的相似度，使得测量中只有加法没有乘法： Y(m,n,t)=-\sum\limits_{i=0}^{d}\sum\limits_{j=0}^{d}\sum\limits_{k=0}^{c_{in}}|X(m+i,n+j,k)-F(i,j,k,t)|使用L1距离存在的问题及解决：问题1：加法滤波器的输出总为负数（会影响激活函数如ReLU的使用） 解决方法：使用Batch Normalization→输出被归一化到适当的范围→CNN中的激活函数在AdderNet中也适用 （BN中存在乘法，但是数量太少可以忽略） 问题2.1：优化方法中滤波器F梯度的计算 AdderNet中计算偏微分： \frac{\partial Y(m,n,t)}{\partial F(i,j,k,t)}=sgn(X(m+i,n+j,k)-F(i,j,k,t))所以梯度取值只有+1，0，-1。由此进行优化的方法为signSGD，但是，signSGD几乎永远不会沿着最陡的下降方向，并且方向性只会随着维数的增长而变差。 解决方法：使用另一种形式的梯度（实际上是L2范数的梯度）： \frac{\partial Y(m,n,t)}{\partial F(i,j,k,t)}=X(m+i,n+j,k)-F(i,j,k,t)问题2.2：优化方法中特征图X梯度的计算 同样使用L2范数的梯度，但是梯度值可能会在[-1，+1]的范围之外→由于chain rule，Y对X的偏导数不仅影响当前层的梯度，还会影响当前层之前的所有层的梯度→梯度爆炸 解决方法：使用HardTanh函数（HT(x)）将X的梯度clip到[-1,+1]的范围。 \frac{\partial Y(m,n,t)}{\partial X(i,j,k,t)}=HT(F(m+i,n+j,k)-X(i,j,k,t))问题3：AdderNet使用L1范数得到的Y方差更大，导致滤波器权重的梯度消失问题 假设F和X服从正太分布 CNN中有 Var[Y_{CNN}]=\sum\limits_{i=0}^{d}\sum\limits_{j=0}^{d}\sum\limits_{k=0}^{c_{in}}Var[X\times F]=d^{2}c_{in}Var[X]Var[F]而AdderNet中则是 Var[Y_{AdderNet}]=\sum\limits_{i=0}^{d}\sum\limits_{j=0}^{d}\sum\limits_{k=0}^{c_{in}}Var[|X-F|]=(1-\frac{2}{\pi})d^{2}c_{in}(Var[X]+Var[F])实际情况中Var[F]非常小，所以$Var[Y_{AdderNet}]$会比$Var[Y_{CNN}]$大。在加法层后面会接一个BN层，大方差会导致X的梯度幅值小，经过chain rule的作用，滤波器的权重梯度幅值会越来越小。 解决方法：adaptive learning rate \triangle F_{l}=\gamma \times \alpha_{l}\times \triangle L(F_{l})$l$：表示第$l$层；$\triangle L(F_{l})$第$l$层F的梯度；$\gamma$：全局学习率 局部学习率： \alpha_{l}=\frac{\eta \sqrt k}{||\triangle L(F_{l})||_{2}}k：F中的元素数量，用于对L2范数求平均 Results在MNIST、CIFAR10、CIFAR100、ImageNet上达到与CNN相近的准确率。 AdderNet的权重服从拉普拉斯分布，而CNN的权重服从高斯分布。 AdderNet: DoWe Really Need Multiplications in Deep Learning? AdderNet代码]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>paper notes-deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Latex中插入python代码]]></title>
    <url>%2F2020%2F10%2F15%2F11_latex_python_code%2F</url>
    <content type="text"><![CDATA[在Latex中插入Python代码，需要一个第三发的宏包pythonhighlight: https://github.com/olivierverdier/python-latex-highlighting 下载pythonhighlight.sty后，将它放到你的.tex文件所在目录下。 然后声明要使用pythonhighlight，在tex文件内的导言区： 12\usepackage&#123;graphicx&#125;\usepackage&#123;pythonhighlight&#125; 之后既可以在正文添加代码了: 12345678910\begin&#123;python&#125;import torchimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as Fimport torchvisionimport torchvision.transforms as transformsimport timeimport os\end&#123;python&#125; 效果如下：]]></content>
      <categories>
        <category>Latex Trick</category>
      </categories>
      <tags>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Valine：为博客添加评论]]></title>
    <url>%2F2020%2F10%2F15%2F12_hexo_valine%2F</url>
    <content type="text"><![CDATA[注册Leancloud账号：https://www.leancloud.cn 注册完以后需要创建一个应用，名字可以随便起，然后 进入应用-&gt;设置-&gt;应用key 拿到你的appid和appkey之后，打开主题配置文件（我是…\themes\next_config.yml） 搜索 valine，填入appid 和 appkey 1234567891011121314valine: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version appid: XO7jV马赛克zGzoHsz # Your leancloud application appid appkey: Amg1Fl马赛克2NfhcO # Your leancloud application appkey notify: false # Mail notifier. See: https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: Just go go # Comment box placeholder avatar: mm # Gravatar style guest_info: nick,mail,link # Custom comment header pageSize: 10 # Pagination size language: # Language, available values: en, zh-cn visitor: false # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors' for counter compatibility. Article reading statistic https://valine.js.org/visitor.html comment_count: true # If false, comment count will only be displayed in post page, not in home page #post_meta_order: 0 最后在Leancloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名加进去 刷新一下~ 看到评论框了 删除评论登录Leancloud&gt;选择你创建的应用&gt;存储&gt;选择ClassComment 参考： https://blog.csdn.net/blue_zy/article/details/79071414 https://github.com/xCss/Valine/issues/69]]></content>
      <categories>
        <category>Setup</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyQt的安装以及在PyCharm上的部署]]></title>
    <url>%2F2020%2F05%2F12%2F08_setup_pyqt%E5%9C%A8pycharm%E4%B8%8A%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[PyQt5安装12pip install pyqt5pip install pyqt5-tools 第二个命令包含了designer的安装。我的designer.exe安装路径在E:\Anaconda3\Library\bin 可以用Cotana搜索designer，然后右键打开文件所在位置，直接定位它的安装路径，后面要用到。 designer在PyCharm上部署File-&gt;Settings-&gt;Tools-&gt;External Tools 点击“+”来增加外部工具。 (1) 增加QT设计界面“Qt Designer” — 这个就是设计Qt界面的工具 Program选择PyQt安装目录中 designer.exe 的路径 Work directory 使用变量 $ProjectFileDir$ （点击后面的Insert Macro…） (2) 增加“PyUIC” — 这个主要是用来将 Qt界面 转换成 py代码 Program选择PyQt安装目录中 pyuic5.bat 的路径（我的依然在E:\Anaconda3\Library\bin里） parameters设置为$FileName$ -o $FileNameWithoutExtension$.py Work directory 设置为 $ProjectFileDir$ （点击后面的Insert Macro…） 点击确认就设置好了。返回去后通过Tools可以看到： 设计GUI依照上图，点击PyQt Designer, 在弹出来的界面中选择Wdiget，然后点击创建。 在窗口添加控件，Lable、pushButton、checkBox、lineEdit等： 把.ui文件保存到当前项目目录中，然后右键点击.ui文件： 点击PyUIC即可将.ui转成.py文件。 在login.py中添加： 12345678if __name__=="__main__": import sys app=QtWidgets.QApplication(sys.argv) widget=QtWidgets.QWidget() ui=Ui_form() ui.setupUi(widget) widget.show() sys.exit(app.exec_()) 运行login.py，就可以看到这个页面了。 QtDesigner的安装 设计GUI]]></content>
      <categories>
        <category>Setup</category>
      </categories>
      <tags>
        <tag>setup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows更改pip镜像源及解决总是timeout的情况]]></title>
    <url>%2F2020%2F05%2F12%2F07_setup_pip%E9%95%9C%E5%83%8F%E6%BA%90%2F</url>
    <content type="text"><![CDATA[pip安装事情的起因是我想安装PyQt5： 12pip install pyqt5pip install pyqt5-tools 当然这是最慢的方法，于是可以用镜像源安装： pip安装使用国内镜像源1234567891011清华：https://pypi.tuna.tsinghua.edu.cn/simple阿里云：http://mirrors.aliyun.com/pypi/simple/中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/华中理工大学：http://pypi.hustunique.com/山东理工大学：http://pypi.sdutlinux.org/ 豆瓣：http://pypi.douban.com/simple/ 临时使用的话加参数-i，例如： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyqt5 然而依然总是timeout，于是： 设置pip配置文件配置文件地址：（如果没有pip.ini文件，就自己新建编辑一个） 1C:\ProgramData\pip\pip.ini 配置文件内容，将召唤timeout的时长设置得长一些 12345678[global]timeout = 60index-url = http://pypi.douban.com/simpletrusted-host = pypi.douban.com[install]use-mirrors = truemirrors = http://pypi.douban.comtrusted-host = pypi.douban.com 设置好之后，再用 1pip install pyqt5 会显示现在使用的是豆瓣镜像源，速度也飞起来了。 pip安装PyQt5 pip使用国内镜像源 pip配置文件设置]]></content>
      <categories>
        <category>Setup</category>
      </categories>
      <tags>
        <tag>setup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch计算模型运算量的工具--torchstat]]></title>
    <url>%2F2020%2F05%2F11%2F06_pytorch_torchstat%2F</url>
    <content type="text"><![CDATA[说明与安装这个包可以计算出一个网络模型的参数量和运算量，甚至给出每一层的运算量，比如： 安装方法为： 1pip install torchstat 示例12345678910111213141516171819202122232425262728import torchimport torch.nn as nnimport torch.nn.functional as Ffrom torchstat import statclass Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(56180, 50) self.fc2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 56180) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x, dim=1)if __name__ == '__main__': model = Net() stat(model, (3, 224, 224)) 然后在命令行输入 1torchstat -f example.py -m Net 如果要更改输入图像的尺寸，只改example.py里的（3，224，224）没有起作用，于是我使用了-s选项： 1torchstat -f example.py -m Net -s &#39;3x32x32&#39; 这里选项内容是用字符串表示的，‘x’就是字母x。 另一个示例12345from torchstat import statimport torchvision.models as modelsmodel = models.resnet18()stat(model, (3, 224, 224)) torchstat的Github]]></content>
      <categories>
        <category>PyTorch Tools</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记(1)：NAS之DARTS]]></title>
    <url>%2F2020%2F04%2F26%2F20200426_NAS_DARTS%2F</url>
    <content type="text"><![CDATA[Search Space搜索cell作为网络结构的构件。cell是包含N个结点的有序序列的有向无环图。结点$x^{(i)}$是隐藏表达（比如卷积网络的特征图），而有向边$(i ,j)$则关联着变换$x^{(i)}$的一些操作$o^{(i,j)}$。文章中假定一个cell中有两个输入节点和一个输出节点。对于卷积cell，输入节点被定义为当前层的前面两层的cell的输出。当前cell的输出是对所有中间节点使用一个压缩操作（比如拼接）得到的。 每一个中间结点基于其所有前向操作计算得到： x^{(j)}=\sum_{i]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>paper notes-deep learning</tag>
      </tags>
  </entry>
</search>
